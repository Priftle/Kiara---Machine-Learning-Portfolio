{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ch1\u003eK-NN Classification\u003c/h1\u003e\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "K-NN classificantion is a branch of supervised learning within the classificantion class.\n",
                "\n",
                "K-NN classification uses data point proximity to group items which posses similar characteristics. A value k is then decided which dictate how many nearest neighbors will be considered for the prediction of a new data point."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  \n"
                }
            ],
            "source": [
                "# Import librarys\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.metrics import f1_score\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# Assign data values held in \"diabetes.csv\" to data variable\n",
                "data = pd.read_csv(\"diabetes.csv\")\n",
                "print(data.head()) # Print first five rows of \"data\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "0      72.0\n1      66.0\n2      64.0\n3      66.0\n4      40.0\n       ... \n763    76.0\n764    70.0\n765    72.0\n766    60.0\n767    70.0\nName: BloodPressure, Length: 768, dtype: float64\n155\n"
                }
            ],
            "source": [
                "# Replace zero values \n",
                "replace_zero = ['Glucose', 'BloodPressure', 'Age','BMI', 'Insulin']\n",
                "\n",
                "# Loop function runs through the data and replace zeroes with the column mean (average)\n",
                "for column in replace_zero:\n",
                "    data[column] = data[column].replace(0, np.NaN)\n",
                "    mean = int(data[column].mean(skipna=True))\n",
                "    data[column].fillna(mean, inplace=True)\n",
                "\n",
                "# This model will predict relation between BloodPressure and the diagnosis of diabetes\n",
                "print(data['BloodPressure'])\n",
                "print(mean)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Splits the dataset into train (creating the model) and test (validation) sets\n",
                "x = data.iloc[:, 0:8] # Keeps all rows, exept for column 8\n",
                "y = data.iloc[:, 8] #  Removes all data exept from that held in column 8, showing whether or not a person has diabetes\n",
                "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Attribute scaling\n",
                "sc_x = StandardScaler() # Sets all data between -1 and 1\n",
                "x_train = sc_x.fit_transform(x_train)\n",
                "x_test = sc_x.transform(x_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "154\n"
                },
                {
                    "data": {
                        "text/plain": "12.409673645990857"
                    },
                    "execution_count": 94,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Determine the hyperparaneter value (the number of nearest neighbors to consider)\n",
                "import math\n",
                "print(len(y_test))\n",
                "math.sqrt(len(y_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cstyle\u003e#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}\u003c/style\u003e\u003cdiv id=\"sk-container-id-12\" class=\"sk-top-container\"\u003e\u003cdiv class=\"sk-text-repr-fallback\"\u003e\u003cpre\u003eKNeighborsClassifier(metric=\u0026#x27;euclidean\u0026#x27;, n_neighbors=11)\u003c/pre\u003e\u003cb\u003eIn a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. \u003cbr /\u003eOn GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u003c/b\u003e\u003c/div\u003e\u003cdiv class=\"sk-container\" hidden\u003e\u003cdiv class=\"sk-item\"\u003e\u003cdiv class=\"sk-estimator sk-toggleable\"\u003e\u003cinput class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked\u003e\u003clabel for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\"\u003eKNeighborsClassifier\u003c/label\u003e\u003cdiv class=\"sk-toggleable__content\"\u003e\u003cpre\u003eKNeighborsClassifier(metric=\u0026#x27;euclidean\u0026#x27;, n_neighbors=11)\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
                        "text/plain": "KNeighborsClassifier(metric='euclidean', n_neighbors=11)"
                    },
                    "execution_count": 95,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Define the model: Init K-NN\n",
                "classifier = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean')\n",
                "classifier.fit(x_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
                    },
                    "execution_count": 96,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Prediction of weather or not someone has diabetes, one representing if someone has it and zero is someone dosent have it\n",
                "y_pred = classifier.predict(x_test)\n",
                "y_pred"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[89 18]\n [16 31]]\n0.6458333333333333\n"
                }
            ],
            "source": [
                "# Evaluate the model\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "print(cm)\n",
                "print(f1_score(y_test, y_pred))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Interpretation of results -\n",
                "[[89, 18][16, 31]]\n",
                "\u003ctable\u003e \n",
                "\u003ctr\u003e \n",
                "\u003ctd\u003e \u003c/td\u003e\n",
                "\u003ctd\u003e Predicted positive \u003c/td\u003e\n",
                "\u003ctd\u003e Predicted negative \u003c/td\u003e\n",
                "\u003c/tr\u003e\n",
                "\u003ctr\u003e\n",
                "\u003ctd\u003e Actual positive \u003c/td\u003e\n",
                "\u003ctd\u003e 89\u003c/td\u003e\n",
                "\u003ctd\u003e 18\u003c/td\u003e\n",
                "\u003c/tr\u003e\n",
                "\u003ctd\u003e Actual negative \u003c/td\u003e\n",
                "\u003ctd\u003e 16\u003c/td\u003e\n",
                "\u003ctd\u003e 31\u003c/td\u003e\n",
                "\u003c/tr\u003e\n",
                "\u003c/table\u003e\n",
                "\n",
                "TP - 89  \n",
                "FP - 18  \n",
                "TN - 16  \n",
                "FN - 31\n",
                "\n",
                "**Accuracy:** overall correctness of the model's predictions \n",
                "\n",
                "formula = (TP + TN) / (TP + FP + TN + FN).  \n",
                "personal accuracy = (89 + 16) / (89 + 18 + 16 + 31) ≈ 0.6818 or 68.18%.\n",
                "\n",
                "\n",
                "**Precision:** measures the accuracy of the positive predictions\n",
                "\n",
                "formula = TP / (TP + FP).  \n",
                "personal precision = 89 / (89 + 18) ≈ 0.8317 or 83.17%.\n",
                "\n",
                "\n",
                "**Recall** (Sensitivity): measures the ability of the model to correctly identify positive instances \n",
                "\n",
                "formula = TP / (TP + FN).  \n",
                "personal recall = 89 / (89 + 31) ≈ 0.7416 or 74.16%.\n",
                "\n",
                "\n",
                "**F1-Score**: the harmonic mean of precision and recall \n",
                "\n",
                "formula = 2 * (Precision * Recall) / (Precision + Recall).  \n",
                "personal F1-Score = 2 * (0.8317 *  0.7416) / (0.8317 + 0.7416) ≈ 0.3920 or 39.2%.\n",
                "\n",
                "From this interpretation, this project's precision and recall are relativly good but the F1-scope and accuracy are not."
            ]
        }
    ]
}
